{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GazizovK/Coursera-HSE-Introduction-to-DL/blob/master/RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRV710Va_T6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "cb7bd42e-512a-45d9-9a70-5571bf7d9503"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-29 15:02:49--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-29 15:02:49 (49.7 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ_tmf8z_IsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d07b6c73-878f-4ae3-8a31-ed0c517b1d47"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLnr48bL_Isi",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "8jhb4Rv2_Isl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5f9471a8-d035-47d5-f0b4-056b4e9373cc"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWggkLk2_Is0",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "SrCPUpkd_Is2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "DXcSUrXT_ItB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "eade5b7f-9d31-4d45-d5fb-8141b177de7f"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "DLI0V25z_ItK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "e19bec95-4a9c-4d2f-bbd4-4523fdc04266"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZimVkhnC9gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9xs0_Nz_ItU",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "V_TlY4JL_ItX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "964fae39-64c1-4706-e520-1d664b9dae1f"
      },
      "source": [
        "tokens = set()\n",
        "for name in names:\n",
        "  tokens = tokens.union(set(name))\n",
        "\n",
        "### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens = ['#'] + list(tokens)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKUPM-MD_Ith",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "oFiWX8-D_Iti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "token_to_id = dict(zip(tokens, np.arange(len(tokens))))\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "zvW6zu2e_Itp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "_RfBx5yK_Itx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a0cb17e2-1906-4aaa-b9e6-d8c856852327"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 9 54 16 10 26 10 28 20  0]\n",
            " [ 9 52 20 35  3 48  0  0  0]\n",
            " [ 9 31  3  5  2  2  5 28  0]\n",
            " [ 9 52  5 35 51 10 24 24 28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vv9RGgp_It6",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "1B1mUqFB_It7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "16ecbdc3-0308-4567-c037-bff925dfb2b0"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "UPgI9gNY_IuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "### YOUR CODE HERE\n",
        "get_h_next = Dense(rnn_num_units, activation = 'tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "### YOUR CODE HERE\n",
        "get_probas = Dense(n_tokens, activation = 'softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueC7Vw0-_IuM",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "fIBYzD82_IuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    ### YOUR CODE HERE\n",
        "    x_and_h = concatenate([x_t_emb, h_t])\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    ### YOUR CODE HERE\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    ### YOUR CODE HERE\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSpTzSG0_IuW",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "QZIMM_Ar_IuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b6401c01-4334-4c01-f65b-af03e55614d2"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXQngUzs_Iug",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "3p8L9Q5x_Iui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj5aVx2__Iuq",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "RIxJRpVU_Ius",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "780b059a-27ac-4148-9021-a0e371dc5e0a"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "### YOUR CODE HERE\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-nUFcVR_Iuy",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "qUuSFa9x_Iuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8ebf69b9-578a-409d-cb66-6cedbd3ed08f"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KkQZjZA_Iu5",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "siVU9BtI_Iu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "JaRLLrQf_IvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "x2f57eyk_IvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "8f1f3850-1ba9-4f8e-d20f-a853d5ca180c"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Teynn\n",
            " Jasy\n",
            " Canrira\n",
            " Heeltof\n",
            " Manlett\n",
            " Ennart\n",
            " Dinthonsos\n",
            " Fuy\n",
            " Caronni\n",
            " Natyi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "n5bXcdIh_IvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "a0d4fb4f-1854-417d-dfd0-f4e04c4e7321"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumploen\n",
            " Trumpien\n",
            " Trumpserd\n",
            " Trumpny\n",
            " Trumpela\n",
            " Trumpe\n",
            " Trumpan\n",
            " Trumpelfa\n",
            " Trumpie\n",
            " Trumpy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRuqt4uo_IvW",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "PrYaqlyc_IvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"EKKNk681OoM2wCi6\"\n",
        "COURSERA_EMAIL = \"gazizov.kb@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "JQpFJfaY_Ivh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "92930536-4508-4e25-dd3a-a6e0f96a132f"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVJINLx8_Ivr",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ixSHxH-O_Ivu",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "cyDT6tQ3_Ivw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "d6d0bca8-80e5-4c3c-8242-147c88f58c67"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-26-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-KUl86__Iv2",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "Ve8jExoo_Iv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "8U_PYX2X_Iv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}